---
title: >
  Experimental Design - exercises
subtitle: >
  CSAMA 2023
author:
- name: <a href="https://csoneson.github.io">Charlotte Soneson (charlotte.soneson@fmi.ch)</a>
date: "2023-06-12"
output: 
  bookdown::html_document2:
    toc: true
    toc_float: true
    theme: cosmo
    code_folding: show
    code_download: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#",
  error = FALSE,
  warning = FALSE,
  message = FALSE
)

suppressPackageStartupMessages({
    require(BiocStyle)
    require(ConfoundingExplorer)
})
htmltools::tagList(rmarkdown::html_dependency_font_awesome())
```

```{r, eval=!exists("SCREENSHOT"), include=FALSE}
SCREENSHOT <- function(x, ...) knitr::include_graphics(x)
```

# Introduction

This vignette contains examples generated with [`ConfoundingExplorer`](https://github.com/csoneson/ConfoundingExplorer). 

The package can be installed from GitHub:

```{r, eval=FALSE}
install.packages("remotes")
remotes::install_github("csoneson/ConfoundingExplorer")
```

After installing the package, an app can be launched by typing 

```{r, eval=FALSE}
library(ConfoundingExplorer)
ConfoundingExplorer()
```

in the R console.

# Overview of the interface

```{r, echo=FALSE}
app <- ConfoundingExplorer()
```

```{r, echo=FALSE}
SCREENSHOT("screenshots/confoundingexplorer-default-settings.png",
           vwidth = 1300)
```

The `ConfoundingExplorer` interface consists of two parts - a sidebar to the 
left where the user can change the settings and the experimental design, and 
a collection of panels displaying various aspects of the generated data and 
results from statistical tests. The main purpose of the app is to evaluate the
ability to correctly detect differentially expressed features between two 
conditions, when the samples may be collected in different batches. 

A detailed description of how the data is generated can be found by clicking 
on the `Data description` button in the bottom of the sidebar, but briefly, 
a base matrix with 1,000 features (rows) and the number of samples (columns) 
equal to the sum of the numbers in the table in the top of the sidebar is 
first generated by random draws from a normal distribution with mean 10 and 
standard deviation 2. Next, condition effects and batch effects are added 
or subtracted from the samples from a given condition or batch. The strength of 
the condition and batch signals can be modified using the sliders in the 
sidebar, and the number of samples in each condition and batch can be changed 
by modifying the table in the top-left corner. 

The `Analysis approach` section of the sidebar determines how the generated 
data will be analysed. In each case, a linear model will be used to compare the 
values for each feature between the two conditions, but depending on the 
choice, the batch effect will be accounted for in different ways. Again, more 
details can be obtained by clicking on the `Data description` button. 

The first row of panels in the main window illustrate the results of the 
statistical test. The left panel shows the number of features in each 
category (affected by condition effect and/or by batch effect), and the 
features that are detected as significantly differentially expressed between 
the conditions are colored in red. The right panel shows a histogram of all the 
1,000 p-values. If there is no signal in the data (no truly differentially 
expressed features) we expect this histogram to show a uniform distribution. 
If there are some truly differential features, we expect additionally a peak 
close to p=0. A peak close to p=1 often indicates a problem with the data, e.g., 
a factor that affects the data but that is not accounted for in the analysis. 

The next panel (`Summary`) provides a summary of the statistical test results. 
More precisely, it shows the TPR (true positive rate, or power - the fraction 
of the features that are truly affected by the condition that are detected 
as significantly differential), the FDP (false discovery proportion - the 
fraction of the features detected as significant that are false positives), 
and the FPR (false positive rate - the fraction of the truly non-differential 
features that are nevertheless found to be significant). 

The `Data heatmap` shows the simulated data in the form of a heatmap. It also 
indicates the condition and batch assignment of the samples (here shown in the 
rows), and the true designation of the features (batch- and/or 
condition-affected) as well as whether they are detected as significantly 
differential between the two conditions. 

Finally, the last row of panels show examples from each of the four 
categories of features (same categories as in the top-right panel). A new set 
of examples can be obtained by clicking on the `New selection` button. 

# Non-confounded setup

First, we consider the setup where there is no confounding between the condition (group) and the batch. 
In other words, each condition is equally represented in each of the batches. 
We will assume that 25% of the features are truly different between the two conditions, and that 50% of the features are affected by the batch. 
The two sets of genes overlap partly. 
Thus, some features that are truly different between conditions are also affected by the batch. 

## Don't adjust for the batch effect

We first consider the results if we don't adjust for the batch effect at all, and just compare the two conditions. 
Since each condition contains samples from both batches, the within-condition variance estimate will also incorporate the differences induced by the batch effect, and thus be artificially inflated compared to the 'true' (within-batch) within-condition variance. 
The effect on the results of the test comparing the two conditions is that we will have lower power to detect true differences (due to the overestimated variance).

```{r}
app <- ConfoundingExplorer(
    sampleSizes = matrix(rep(5, 4), nrow = 2,
                         dimnames = list(c("group1", "group2"),
                                         c("batch1", "batch2"))),
    fracVarCond = 0.25,
    fracVarBatch = 0.5,
    condEffectSize = 4,
    batchEffectSize = 4,
    analysisApproach = "dontAdjust"
)
```

```{r, echo=FALSE}
SCREENSHOT("screenshots/confoundingexplorer-5-5-5-5-0.25-0.5-4-4-dontAdjust.png",
           vwidth = 1300)
```

## Increase the size of the batch effect, don't adjust

To see the effect described above even clearer, let's increase the size of the batch effect. 
This simulates a situation where, for example, five replicates of each condition were obtained by each of two technologies, or using completely different protocols.
Now we see the loss of power much more strikingly, and we notice a strangely shaped p-value histogram. 

```{r}
app <- ConfoundingExplorer(
    sampleSizes = matrix(rep(5, 4), nrow = 2,
                         dimnames = list(c("group1", "group2"),
                                         c("batch1", "batch2"))),
    fracVarCond = 0.25,
    fracVarBatch = 0.5,
    condEffectSize = 4,
    batchEffectSize = 10,
    analysisApproach = "dontAdjust"
)
```

```{r, echo=FALSE}
SCREENSHOT("screenshots/confoundingexplorer-5-5-5-5-0.25-0.5-4-10-dontAdjust.png",
           vwidth = 1300)
```

## Adjust for the batch effect by including it as a covariate

The recommended way of adjusting for batch effects in statistical modeling is to include them as a covariate (an 'additional predictor variable') in the model. 
Here we follow this approach, and thus model the observed values as a linear combination of the estimated batch effect and the estimated condition effect. 
As before, the p-values correspond to the test of the condition effect (but now we're accounting for the batch effect).
We note that by including the extra predictor corresponding to the batch effect, we can explain some of the between-sample variance and thus increase the power to detect differences. 

```{r}
app <- ConfoundingExplorer(
    sampleSizes = matrix(rep(5, 4), nrow = 2,
                         dimnames = list(c("group1", "group2"),
                                         c("batch1", "batch2"))),
    fracVarCond = 0.25,
    fracVarBatch = 0.5,
    condEffectSize = 4,
    batchEffectSize = 4,
    analysisApproach = "inclBatch"
)
```

```{r, echo=FALSE}
SCREENSHOT("screenshots/confoundingexplorer-5-5-5-5-0.25-0.5-4-4-inclBatch.png",
           vwidth = 1300)
```

# Fully confounded setup

Next, we consider a fully confounded setup.
Here, the 10 replicates of each condition were all acquired in the same batch, and only samples from one condition were included in each batch. 

## Don't adjust for the batch effect

If we do not adjust for the batch effect in this case, both the batch and condition effects are interpreted as the condition effect, which leads to a high false positive rate.
In other words, many features are interpreted as being different between the two conditions, whereas the difference in reality is caused by the batch effect, which is completely confounded with the condition. 
In addition, some features that are truly differential between the two conditions are no longer detected, since the difference is counteracted by the batch effect.

```{r}
app <- ConfoundingExplorer(
    sampleSizes = matrix(c(10, 0, 0, 10), nrow = 2,
                         dimnames = list(c("group1", "group2"),
                                         c("batch1", "batch2"))),
    fracVarCond = 0.25,
    fracVarBatch = 0.5,
    condEffectSize = 4,
    batchEffectSize = 4,
    analysisApproach = "dontAdjust"
)
```

```{r, echo=FALSE}
SCREENSHOT("screenshots/confoundingexplorer-10-0-0-10-0.25-0.5-4-4-dontAdjust.png",
           vwidth = 1300)
```

## Attempt to adjust for the batch effect

In the non-confounded situation above, we could adjust for the batch effect by including it as a covariate in the model. 
When the batch and condition factors are fully confounded, however, this is not possible, since it would mean including two perfectly correlated predictors in the model. 

```{r}
app <- ConfoundingExplorer(
    sampleSizes = matrix(c(10, 0, 0, 10), nrow = 2,
                         dimnames = list(c("group1", "group2"),
                                         c("batch1", "batch2"))),
    fracVarCond = 0.25,
    fracVarBatch = 0.5,
    condEffectSize = 4,
    batchEffectSize = 4,
    analysisApproach = "inclBatch"
)
```

```{r, echo=FALSE}
SCREENSHOT("screenshots/confoundingexplorer-10-0-0-10-0.25-0.5-4-4-inclBatch.png",
           vwidth = 1300)
```

# Partly confounded setup

Finally, we consider a partly confounded setup. Here, each batch contains 9 samples of one condition and 1 sample of the other condition. 

## Adjust for the batch effect by including it as a covariate

As in the non-confounded case, we attempt to adjust for the batch effect by including it as a covariate in the model. 
While it is now statistically feasible (as opposed to the fully confounded case), we notice that the power to detect true differences between the conditions is lower than in the non-confounded case. 

```{r}
app <- ConfoundingExplorer(
    sampleSizes = matrix(c(9, 1, 1, 9), nrow = 2,
                         dimnames = list(c("group1", "group2"),
                                         c("batch1", "batch2"))),
    fracVarCond = 0.25,
    fracVarBatch = 0.5,
    condEffectSize = 4,
    batchEffectSize = 4,
    analysisApproach = "inclBatch"
)
```

```{r, echo=FALSE}
SCREENSHOT("screenshots/confoundingexplorer-9-1-1-9-0.25-0.5-4-4-inclBatch.png",
           vwidth = 1300)
```

## Remove the batch effect in advance

Another approach that is sometimes used, especially when the data is going to be used for exploratory analysis rather than statistical modeling, is to estimate the batch effect in advance, and subtract it from the observed values. 
Here we illustrate this approach for the partly confounded setup. 
We notice that almost all the true signal is removed by this procedure, since we do not inform the batch effect correction step of the condition effect, and thus any signal that could potentially be explained by the batch variable will be removed. 

```{r}
app <- ConfoundingExplorer(
    sampleSizes = matrix(c(9, 1, 1, 9), nrow = 2,
                         dimnames = list(c("group1", "group2"),
                                         c("batch1", "batch2"))),
    fracVarCond = 0.25,
    fracVarBatch = 0.5,
    condEffectSize = 4,
    batchEffectSize = 4,
    analysisApproach = "removeBatch"
)
```

```{r, echo=FALSE}
SCREENSHOT("screenshots/confoundingexplorer-9-1-1-9-0.25-0.5-4-4-removeBatch.png",
           vwidth = 1300)
```

## Remove batch effect in advance, accounting for the condition

As an alternative to the approach outlined in the previous section, we could inform the batch effect adjustment step of the condition factor, and instruct it to not remove any effect that could be explained by the latter. 
Since the batch and condition factors are highly similar, the effect of this is that very little of the batch effect is in fact eliminated. 

```{r}
app <- ConfoundingExplorer(
    sampleSizes = matrix(c(9, 1, 1, 9), nrow = 2,
                         dimnames = list(c("group1", "group2"),
                                         c("batch1", "batch2"))),
    fracVarCond = 0.25,
    fracVarBatch = 0.5,
    condEffectSize = 4,
    batchEffectSize = 4,
    analysisApproach = "removeBatchAccCond"
)
```

```{r, echo=FALSE}
SCREENSHOT("screenshots/confoundingexplorer-9-1-1-9-0.25-0.5-4-4-removeBatchAccCond.png",
           vwidth = 1300)
```

# Conclusion

The examples above illustrate the complications that arise when the condition of interest is (partly or fully) confounded with a batch effect or another source of unwanted variation affecting the data. 
It is important to note that in a fully confounded experimental setup, statistical modeling can never 'rescue' the experiment, and there is no reliable way of distinguishing the effect of the batch and the condition, respectively. 
In a non-confounded experiment, even if there is a batch effect, it can typically be accounted for in the statistical modeling. 

# Session info

```{r}
sessionInfo()
```
